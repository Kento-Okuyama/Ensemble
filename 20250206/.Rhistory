model_ar <- SSModel(
Y ~ -1 + SSMcustom(
Z = diag(1, nrow = N),
T = diag(NA, nrow = N),
R = diag(1, nrow = N),
Q = diag(NA, nrow = N),
state_names = paste0("state_", 1:N)
),
H = diag(NA, nrow = N)
)
# 3) updatefn
updatefn_ar <- function(pars, model) {
# pars[1] => phi, mapped to (-1,1) via tanh
# pars[2] => sigma_q = exp(pars[2])
# pars[3] => sigma_h = exp(pars[3])
phi  <- tanh(pars[1])
sigQ <- exp(pars[2])
sigH <- exp(pars[3])
model$T[,,1] <- diag(phi, nrow = N)
model$Q[,,1] <- diag(sigQ^2, nrow = N)
model$H[,,1] <- diag(sigH^2, nrow = N)
return(model)
}
# 4) fitSSM
fit_ar <- fitSSM(
model   = model_ar,
inits   = c(0.0, log(0.1), log(0.1)),
updatefn = updatefn_ar,
method  = "BFGS"
)
# 5) Filter & Smoother (stateを指定)
kfs_ar <- KFS(
fit_ar$model,
filtering = c("state","mean"),
smoothing = c("state","mean")
)
# 6) Forecast val+test steps
pred_ar_list <- predict(fit_ar$model, n.ahead = horizon)  # list of ts if N>1
# Convert to numeric matrix: (horizon) x N
pred_ar_mat <- do.call(cbind, lapply(pred_ar_list, as.numeric))
colnames(pred_ar_mat) <- paste0("y", 1:N)
return(list(
fit_ar   = fit_ar,
kfs_ar   = kfs_ar,       # kfs_ar$alphahat がちゃんと入る
pred_ar  = pred_ar_mat   # dimension: horizon x N
))
}
# ============  MA(1) KFAS  ============ #
fit_ma_kfas <- function(data) {
# data$train_y : N x train_Nt
# 1) Reshape
Y <- t(data$train_y)
N <- data$N
train_Nt <- data$train_Nt
val_Nt   <- data$val_Nt
test_Nt  <- data$test_Nt
horizon  <- val_Nt + test_Nt
# 2) Build MA(1) model
model_ma <- SSModel(
Y ~ -1 + SSMcustom(
Z = matrix(NA, nrow = N, ncol = 2*N),
T = matrix(NA, nrow = 2*N, ncol = 2*N),
R = diag(1, nrow = 2*N),
Q = diag(NA, nrow = 2*N),
state_names = c(
paste0("delta_now_", 1:N),
paste0("delta_prev_", 1:N)
)
),
H = diag(NA, nrow = N)
)
# 3) updatefn
updatefn_ma <- function(pars, model) {
# pars[1] = theta
# pars[2] = mu
# pars[3] = log(sigma_ma)
# pars[4] = log(sigma_obs)
theta  <- pars[1]
mu     <- pars[2]
sigSys <- exp(pars[3])
sigObs <- exp(pars[4])
# Shift observations by mu
model$y <- model$y - mu
# Z = [ I_N  0 ]
Z_new <- cbind(diag(1, N), matrix(0, N, N))
model$Z[,,1] <- Z_new
# T = block( zeroN, theta*I; I, zeroN )
zeroN <- matrix(0, N, N)
eyeN  <- diag(1, N)
T_mat <- rbind(
cbind(zeroN,    theta*eyeN),
cbind(eyeN,     zeroN)
)
model$T[,,1] <- T_mat
# Q => noise on "delta_now" part
Q_mat <- rbind(
cbind(sigSys^2 * eyeN, zeroN),
cbind(zeroN,           zeroN)
)
model$Q[,,1] <- Q_mat
# H => observation noise
model$H[,,1] <- diag(sigObs^2, N)
return(model)
}
# 4) fitSSM
fit_ma <- fitSSM(
model = model_ma,
inits = c(0.3, 0.0, log(0.1), log(0.1)),
updatefn = updatefn_ma,
method = "BFGS"
)
# フィルタ & 平滑化 (stateを指定)
kfs_ma <- KFS(
fit_ma$model,
filtering = c("state","mean"),
smoothing = c("state","mean")
)
# 5) Forecast
pred_ma_list <- predict(fit_ma$model, n.ahead = horizon)
# Parameter estimates => add mu back
par_est   <- fit_ma$optim.out$par
theta_hat <- par_est[1]
mu_hat    <- par_est[2]
pred_ma_mat <- do.call(cbind, lapply(pred_ma_list, function(ts_obj) {
as.numeric(ts_obj) + mu_hat
}))
colnames(pred_ma_mat) <- paste0("y", 1:N)
return(list(
fit_ma     = fit_ma,
kfs_ma     = kfs_ma,         # kfs_ma$alphahat がちゃんと入る
theta_hat  = theta_hat,
mu_hat     = mu_hat,
pred_ma    = pred_ma_mat     # (horizon) x N
))
}
# ============  統合関数 (Stan版との互換)  ============ #
fit_apriori_kfas_both <- function(data) {
# 1) AR(1) & MA(1) fit via KFAS
res_ar_kfas <- fit_ar_kfas(data)
res_ma_kfas <- fit_ma_kfas(data)
# 2) Get state estimates
kfs_ar   <- res_ar_kfas$kfs_ar
kfs_ma   <- res_ma_kfas$kfs_ma
alph_ar  <- kfs_ar$alphahat      # now not NULL
alph_ma  <- kfs_ma$alphahat      # now not NULL
# (以下、元のコードとほぼ同じ処理)
# ...
#   - Combine train states + future predictions
#   - Build pred_e, pred_f as 3D arrays
#   - Slice them into train_e, val_e, test_e etc.
# 以下はオリジナルコードのまま（省略）。
# ただし alph_ar, alph_ma が実際に非NULLになったはずなので、
# AR(1)モデルのtrain_Nt x N, MA(1)モデルの train_Nt x (2N) などが取得できます。
#---------------------------------------------
# (同じコードを再掲)
#---------------------------------------------
N        <- data$N
train_Nt <- data$train_Nt
val_Nt   <- data$val_Nt
test_Nt  <- data$test_Nt
horizon  <- val_Nt + test_Nt
# MA(1) => "delta_now" part
alph_ma_now <- alph_ma[, 1:N, drop=FALSE]
e_ar_train <- alph_ar
e_ar_test  <- res_ar_kfas$pred_ar  # horizon x N
e_ar_full  <- rbind(e_ar_train, e_ar_test)
e_ma_train <- alph_ma_now
e_ma_test  <- res_ma_kfas$pred_ma
e_ma_full  <- rbind(e_ma_train, e_ma_test)
e_ar_t <- t(e_ar_full)
e_ma_t <- t(e_ma_full)
pred_e <- array(NA, c(N, train_Nt + val_Nt + test_Nt, 2))
pred_e[,,1] <- e_ar_t
pred_e[,,2] <- e_ma_t
f_ar_train <- alph_ar
f_ar_full  <- rbind(f_ar_train, res_ar_kfas$pred_ar)
f_ar_t     <- t(f_ar_full)
f_ma_train <- alph_ma_now
f_ma_full  <- rbind(f_ma_train, res_ma_kfas$pred_ma)
f_ma_t     <- t(f_ma_full)
pred_f <- array(NA, c(N, train_Nt + val_Nt + test_Nt, 2))
pred_f[,,1] <- f_ar_t
pred_f[,,2] <- f_ma_t
train_e <- pred_e[, 1:train_Nt, ]
val_e   <- pred_e[, (train_Nt+1):(train_Nt+val_Nt), ]
test_e  <- pred_e[, (train_Nt+val_Nt+1):(train_Nt+val_Nt+test_Nt), ]
train_f <- pred_f[, 1:train_Nt, ]
val_f   <- pred_f[, (train_Nt+1):(train_Nt+val_Nt), ]
test_f  <- pred_f[, (train_Nt+val_Nt+1):(train_Nt+val_Nt+test_Nt), ]
data_fit <- list(
N        = data$N,
J        = 2,
train_Nt = data$train_Nt,
val_Nt   = data$val_Nt,
test_Nt  = data$test_Nt,
train_y  = data$train_y,
val_y    = data$val_y,
test_y   = data$test_y,
pred_e   = pred_e,
pred_f   = pred_f,
train_e  = train_e,
val_e    = val_e,
test_e   = test_e,
train_f  = train_f,
val_f    = val_f,
test_f   = test_f
)
# res_ar, res_ma
res_ar <- list(
fit_ar   = res_ar_kfas$fit_ar,
kfs_ar   = res_ar_kfas$kfs_ar
)
res_ma <- list(
fit_ma   = res_ma_kfas$fit_ma,
kfs_ma   = res_ma_kfas$kfs_ma
)
return(list(
data_fit = data_fit,
res_ar   = res_ar,
res_ma   = res_ma
))
}
fit_apriori_kfas_both(df)
res<-fit_apriori_kfas_both(df)
res$data_fit
res$res_ar
res$res_ma
res$res_ma
res$data_fit
# ===========================
#  Clear Workspace and Setup
# ===========================
rm(list = ls())  # Clear all objects from the workspace
# Set the working directory
setwd('C:/Users/kento/OneDrive - UT Cloud (1)/PhD/Ensemble/20250206')
# ===========================
#   Load External Scripts
# ===========================
# Load necessary R scripts for custom functions and models
source('library.R')       # Contains library imports and setups
source('DGP.R')           # Function for data generation process
source('fit_apriori_ar1.R')   # Model fitting function: Apriori
source('fit_apriori_ma1.R')   # Model fitting function: Apriori
source('fit_apriori.R')   # Model fitting function: Apriori
source('fit_BMA.R')       # Model fitting function: Bayesian Model Averaging
source('fit_BPS.R')       # Model fitting function: Bayesian Predictive Stacking
source('fit_BPS2.R')      # Model fitting function: Alternative Bayesian Predictive Stacking
# Load additional libraries using a custom function
library_load()
# ===========================
#  Set Parameters
# ===========================
N <- 10/5
Nt <- 50/5
# ===========================
#   Multiple Runs Setup
# ===========================
n_runs <- 50/50          # Number of iterations
result_list <- list()  # Store results for each run
# ===========================
#   Model Fitting Parameters
# ===========================
n_iter <- 2000/20   # Number of iterations for Stan model
n_chains <- 4/4    # Number of chains for Stan model
# Progress bar setup
pb <- txtProgressBar(min = 0, max = n_runs, style = 3)
i<-1
# Update seed
seed <- 123 + i  # Change seed for each iteration
# Generate data
df <- DGP(N = N, Nt = Nt, seed = seed, train_ratio = 0.6, val_ratio = 0.2)
# Fit models
res_apriori <- fit_apriori(data = df)
res_apriori
res_BMA <- fit_BMA(data = res_apriori$data_fit, iter = n_iter, chains = n_chains, refresh = 0)
res_BMA
# ===========================
#  Clear Workspace and Setup
# ===========================
rm(list = ls())  # Clear all objects from the workspace
# Set the working directory
setwd('C:/Users/kento/OneDrive - UT Cloud (1)/PhD/Ensemble/20250206')
# ===========================
#   Load External Scripts
# ===========================
# Load necessary R scripts for custom functions and models
source('library.R')       # Contains library imports and setups
source('DGP.R')           # Function for data generation process
source('fit_apriori_ar1.R')   # Model fitting function: Apriori
source('fit_apriori_ma1.R')   # Model fitting function: Apriori
source('fit_apriori.R')   # Model fitting function: Apriori
source('fit_BMA.R')       # Model fitting function: Bayesian Model Averaging
source('fit_BPS.R')       # Model fitting function: Bayesian Predictive Stacking
source('fit_BPS2.R')      # Model fitting function: Alternative Bayesian Predictive Stacking
# Load additional libraries using a custom function
library_load()
# ===========================
#  Set Parameters
# ===========================
N <- 10/5
Nt <- 50/2
# ===========================
#   Multiple Runs Setup
# ===========================
n_runs <- 50/50          # Number of iterations
result_list <- list()  # Store results for each run
# ===========================
#   Model Fitting Parameters
# ===========================
n_iter <- 2000/20   # Number of iterations for Stan model
n_chains <- 4/4    # Number of chains for Stan model
# Progress bar setup
pb <- txtProgressBar(min = 0, max = n_runs, style = 3)
for (i in 1:n_runs) {
# Update seed
seed <- 123 + i  # Change seed for each iteration
# Generate data
df <- DGP(N = N, Nt = Nt, seed = seed, train_ratio = 0.6, val_ratio = 0.2)
# Fit models
res_apriori <- fit_apriori(data = df)
res_BMA <- fit_BMA(data = res_apriori$data_fit, iter = n_iter, chains = n_chains, refresh = 0)
res_BPS <- fit_BPS(data = res_apriori$data_fit, iter = n_iter, chains = n_chains, refresh = 0)
res_BPS2 <- fit_BPS2(data = res_apriori$data_fit, iter = n_iter, chains = n_chains, refresh = 0)
# Extract results
results <- data.frame(
run = i,
test_rmse_AR = res_apriori$res_ar$test_rmse,
test_rmse_MA = res_apriori$res_ma$test_rmse,
test_rmse_BMA = res_BMA$test_rmse,
test_rmse_BPS = res_BPS$test_rmse,
test_rmse_BPS2 = res_BPS2$test_rmse
)
# Append to list
result_list[[i]] <- results
# Update progress bar
setTxtProgressBar(pb, i)
}
# ===========================
#  Clear Workspace and Setup
# ===========================
rm(list = ls())  # Clear all objects from the workspace
# Set the working directory
setwd('C:/Users/kento/OneDrive - UT Cloud (1)/PhD/Ensemble/20250206')
# ===========================
#   Load External Scripts
# ===========================
# Load necessary R scripts for custom functions and models
source('library.R')       # Contains library imports and setups
source('DGP.R')           # Function for data generation process
source('fit_apriori_ar1.R')   # Model fitting function: Apriori
source('fit_apriori_ma1.R')   # Model fitting function: Apriori
source('fit_apriori.R')   # Model fitting function: Apriori
source('fit_BMA.R')       # Model fitting function: Bayesian Model Averaging
source('fit_BPS.R')       # Model fitting function: Bayesian Predictive Stacking
source('fit_BPS2.R')      # Model fitting function: Alternative Bayesian Predictive Stacking
# Load additional libraries using a custom function
library_load()
# ===========================
#  Set Parameters
# ===========================
N <- 10/5
Nt <- 50/2
# ===========================
#   Multiple Runs Setup
# ===========================
n_runs <- 50/50          # Number of iterations
result_list <- list()  # Store results for each run
# ===========================
#   Model Fitting Parameters
# ===========================
n_iter <- 2000/20   # Number of iterations for Stan model
n_chains <- 4/4    # Number of chains for Stan model
# Progress bar setup
pb <- txtProgressBar(min = 0, max = n_runs, style = 3)
for (i in 1:n_runs) {
# Update seed
seed <- 123 + i  # Change seed for each iteration
# Generate data
df <- DGP(N = N, Nt = Nt, seed = seed, train_ratio = 0.6, val_ratio = 0.2)
# Fit models
res_apriori <- fit_apriori(data = df)
res_BMA <- fit_BMA(data = res_apriori$data_fit, iter = n_iter, chains = n_chains, refresh = 0)
res_BPS <- fit_BPS(data = res_apriori$data_fit, iter = n_iter, chains = n_chains, refresh = 0)
res_BPS2 <- fit_BPS2(data = res_apriori$data_fit, iter = n_iter, chains = n_chains, refresh = 0)
# Extract results
results <- data.frame(
run = i,
# test_rmse_AR = res_apriori$res_ar$test_rmse,
# test_rmse_MA = res_apriori$res_ma$test_rmse,
test_rmse_BMA = res_BMA$test_rmse,
test_rmse_BPS = res_BPS$test_rmse,
test_rmse_BPS2 = res_BPS2$test_rmse
)
# Append to list
result_list[[i]] <- results
# Update progress bar
setTxtProgressBar(pb, i)
}
# Combine results into a single data frame
final_results <- do.call(rbind, result_list)
# Save results to a CSV file
write.csv(final_results, "model_comparison_results.csv", row.names = FALSE)
# ===========================
#   Analyze Results
# ===========================
# Calculate summary statistics
summary_stats <- final_results %>%
summarise(
across(starts_with("test_rmse"), list(mean = mean, sd = sd))
)
# Print summary statistics
print(summary_stats)
# Optionally, visualize results
rmse_columns <- final_results %>% select(starts_with("test_rmse"))
# Specify the file path and format
png("test_rmse_across_models.png", width = 800, height = 600)
# Create the plot
boxplot(rmse_columns,
main = "Test RMSE across models",
las = 2,
xlab = "Models",
ylab = "Test RMSE",
names = c("AR", "MA", "BMA", "BPS", "BPS2"))
# ===========================
#  Clear Workspace and Setup
# ===========================
rm(list = ls())  # Clear all objects from the workspace
# Set the working directory
setwd('C:/Users/kento/OneDrive - UT Cloud (1)/PhD/Ensemble/20250206')
# ===========================
#   Load External Scripts
# ===========================
# Load necessary R scripts for custom functions and models
source('library.R')       # Contains library imports and setups
source('DGP.R')           # Function for data generation process
source('fit_apriori_ar1.R')   # Model fitting function: Apriori
source('fit_apriori_ma1.R')   # Model fitting function: Apriori
source('fit_apriori.R')   # Model fitting function: Apriori
source('fit_BMA.R')       # Model fitting function: Bayesian Model Averaging
source('fit_BPS.R')       # Model fitting function: Bayesian Predictive Stacking
source('fit_BPS2.R')      # Model fitting function: Alternative Bayesian Predictive Stacking
# Load additional libraries using a custom function
library_load()
# ===========================
#  Set Parameters
# ===========================
N <- 10/5
Nt <- 50/2
# ===========================
#   Multiple Runs Setup
# ===========================
n_runs <- 50/50          # Number of iterations
result_list <- list()  # Store results for each run
# ===========================
#   Model Fitting Parameters
# ===========================
n_iter <- 2000/20   # Number of iterations for Stan model
n_chains <- 4/4    # Number of chains for Stan model
# Progress bar setup
pb <- txtProgressBar(min = 0, max = n_runs, style = 3)
for (i in 1:n_runs) {
# Update seed
seed <- 123 + i  # Change seed for each iteration
# Generate data
df <- DGP(N = N, Nt = Nt, seed = seed, train_ratio = 0.6, val_ratio = 0.2)
# Fit models
res_apriori <- fit_apriori(data = df)
res_BMA <- fit_BMA(data = res_apriori$data_fit, iter = n_iter, chains = n_chains, refresh = 0)
res_BPS <- fit_BPS(data = res_apriori$data_fit, iter = n_iter, chains = n_chains, refresh = 0)
res_BPS2 <- fit_BPS2(data = res_apriori$data_fit, iter = n_iter, chains = n_chains, refresh = 0)
# Extract results
results <- data.frame(
run = i,
# test_rmse_AR = res_apriori$res_ar$test_rmse,
# test_rmse_MA = res_apriori$res_ma$test_rmse,
test_rmse_BMA = res_BMA$test_rmse,
test_rmse_BPS = res_BPS$test_rmse,
test_rmse_BPS2 = res_BPS2$test_rmse
)
# Append to list
result_list[[i]] <- results
# Update progress bar
setTxtProgressBar(pb, i)
}
# Combine results into a single data frame
final_results <- do.call(rbind, result_list)
# Save results to a CSV file
write.csv(final_results, "model_comparison_results.csv", row.names = FALSE)
# ===========================
#   Analyze Results
# ===========================
# Calculate summary statistics
summary_stats <- final_results %>%
summarise(
across(starts_with("test_rmse"), list(mean = mean, sd = sd))
)
# Print summary statistics
print(summary_stats)
# Optionally, visualize results
rmse_columns <- final_results %>% select(starts_with("test_rmse"))
# Specify the file path and format
png("test_rmse_across_models.png", width = 800, height = 600)
# Create the plot
boxplot(rmse_columns,
main = "Test RMSE across models",
las = 2,
xlab = "Models",
ylab = "Test RMSE",
names = c("BMA", "BPS", "BPS2"))
# names = c("AR", "MA", "BMA", "BPS", "BPS2"))
# Close the file
dev.off()
