lambda <- 0.5  # Smoothing parameter for target_mean
mu <- c(2, -2, 1, 0)         # Regime means
ar_pos <- 0.7                # Positive AR coefficient
ar_neg <- -0.7               # Negative AR coefficient
ma_coef <- 0.5               # MA coefficient
sigma <- c(0.5, 0.7, 0.6, 0.4)  # Standard deviations for each regime
# Define transition matrix for regime switching
transition_matrix <- matrix(c(
0.8, 0.05, 0.1, 0.05,
0.1, 0.8, 0.05, 0.05,
0.1, 0.05, 0.8, 0.05,
0.1, 0.05, 0.1, 0.75
), nrow = 4, byrow = TRUE)
# Initialize matrices to store simulated data
y <- matrix(NA, nrow = N, ncol = Nt)
regime <- matrix(NA, nrow = N, ncol = Nt)
# Simulate data with regime transitions
for (n in 1:N) {
current_regime <- 1 # sample(1:4, 1)
y[n, 1] <- rnorm(1, mean = mu[current_regime], sd = sigma[current_regime])  # Initial value
regime[n, 1] <- current_regime
for (t in 2:Nt) {
current_regime <- sample(1:4, 1, prob = transition_matrix[current_regime, ])
regime[n, t] <- current_regime
target_mean <- lambda * mu[current_regime] + (1 - lambda) * y[n, t - 1]
if (current_regime == 1) {
y[n, t] <- (1 - ar_pos) * target_mean + ar_pos * y[n, t-1] + rnorm(1, mean = 0, sd = sigma[current_regime])
} else if (current_regime == 2) {
y[n, t] <- (1 - ar_neg) * target_mean + ar_neg * y[n, t-1] + rnorm(1, mean = 0, sd = sigma[current_regime])
} else if (current_regime == 3) {
y[n, t] <- target_mean + ma_coef * (y[n, t - 1] - target_mean) + rnorm(1, mean = 0, sd = sigma[current_regime])
} else {
y[n, t] <- rnorm(1, mean = target_mean, sd = sigma[current_regime])
}
}
}
# Convert to data frame for ggplot visualization
y_df <- data.frame(
time = rep(1:Nt, times = N),
value = as.vector(y),
series = rep(1:N, each = Nt),
regime = as.vector(regime)
)
# Plot each individual's time series with regime-based coloring
ggplot(y_df, aes(x = time, y = value, group = series, color = as.factor(regime))) +
geom_line(aes(color = as.factor(regime))) +  # Line changes color based on regime
geom_point(size = 1) +  # Add points to emphasize regime switches
facet_wrap(~ series, ncol = 1, scales = "free_y") +  # Separate plots for each individual
labs(title = "Time Series with Regime Switching for Each Individual",
color = "Regime") +
theme_minimal() +
theme(legend.position = "bottom") +
scale_color_manual(values = c("1" = "blue", "2" = "red", "3" = "green", "4" = "purple"))
# Count occurrences of each regime in the simulated data
regime_counts <- y_df %>%
group_by(regime) %>%
summarize(count = n())
# Plot the distribution of regimes
ggplot(regime_counts, aes(x = as.factor(regime), y = count, fill = as.factor(regime))) +
geom_bar(stat = "identity") +
labs(title = "Frequency of Each Regime", x = "Regime", y = "Count") +
theme_minimal()
# Prepare data list for Stan
stan_data <- list(
N = N,
Nt = Nt,
regime = regime,
y = y
)
# Stan model code
stan_code <- "
data {
int<lower=1> N;                   // Number of individuals
int<lower=1> Nt;                  // Time series length for each individual
real y[N, Nt];                    // Observed data
}
parameters {
vector[4] mu;                     // Mean for each state
real<lower=0, upper=1> lambda;    // Smoothing parameter for target mean
real<lower=0, upper=1> ar_pos;    // AR coefficient for state 1
real<lower=-1, upper=0> ar_neg;   // AR coefficient for state 2
real<lower=-1, upper=1> ma_coef;  // MA coefficient for state 3
vector<lower=0>[4] sigma;         // Standard deviation for each state
simplex[4] T[4];                  // Transition probability matrix
}
transformed parameters {
vector[4] w[Nt];               // Dynamic weights
// Initialize weights
w[1] = [1, 0, 0, 0]';
// Update weights based on transition probabilities
for (t in 2:Nt) {
for (j in 1:4) {
w[t][j] = T[1][j] * w[t - 1][1] + T[2][j] * w[t - 1][2] + T[3][j] * w[t - 1][3] + T[4][j] * w[t - 1][4];
}
}
}
model {
real weighted_prediction;
real variance_weighted;
// Prior distributions for parameters
mu ~ normal(0, 5);
lambda ~ beta(2, 2);
ar_pos ~ normal(0.7, 0.3);
ar_neg ~ normal(-0.7, 0.3);
ma_coef ~ normal(0, 0.5);
sigma ~ cauchy(0, 2);
// Priors for transition matrix
for (i in 1:4) {
vector[4] alpha = rep_vector(0.1, 4);
alpha[i] = 0.8;
T[i] ~ dirichlet(alpha);
}
// State-dependent model for each time series
for (n in 1:N) {
for (t in 2:Nt) {
real target_mean = lambda * dot_product(w[t], mu) + (1 - lambda) * y[n, t - 1];
vector[4] y_pred;
// State-specific predictions
y_pred[1] = (1 - ar_pos) * target_mean + ar_pos * y[n, t-1];
y_pred[2] = (1 - ar_neg) * target_mean + ar_neg * y[n, t-1];
y_pred[3] = target_mean + ma_coef * (y[n, t - 1] - target_mean);
y_pred[4] = target_mean;
// Weighted prediction based on dynamic weights
weighted_prediction = dot_product(w[t], y_pred);
variance_weighted = dot_product(w[t], sigma);
// Observation model
y[n, t] ~ normal(weighted_prediction, variance_weighted);
}
}
}
generated quantities {
real weighted_prediction;
real variance_weighted;
matrix[N, Nt-1] y_rep;             // Posterior predictive samples
matrix[N, Nt-1] log_lik;           // Log-likelihood for LOO
for (n in 1:N) {
for (t in 2:Nt) {
real target_mean = lambda * dot_product(w[t], mu) + (1 - lambda) * y[n, t - 1];
vector[4] y_pred;
y_pred[1] = (1 - ar_pos) * target_mean + ar_pos * y[n, t-1];
y_pred[2] = (1 - ar_neg) * target_mean + ar_neg * y[n, t-1];
y_pred[3] = target_mean + ma_coef * (y[n, t-1] - target_mean);
y_pred[4] = target_mean;
weighted_prediction = dot_product(w[t], y_pred);
variance_weighted = dot_product(w[t], sigma);
y_rep[n, t-1] = normal_rng(weighted_prediction, variance_weighted);
log_lik[n, t-1] = normal_lpdf(y[n, t] | weighted_prediction, variance_weighted);
}
}
}
"
# Compile and sample from the Stan model
fit <- stan(model_code = stan_code, data = stan_data, iter = 2000, chains = 4)
# Compile and sample the Stan model
# fit <- stan(
#   model_code = stan_code,
#   data = stan_data,
#   iter = 4000,             # Increase number of iterations to improve convergence and ESS
#   chains = 4,
#   control = list(
#     adapt_delta = 0.99,    # Set adapt_delta to 0.99 to reduce divergent transitions
#     max_treedepth = 15     # Increase max_treedepth to 15 for better exploration of parameter space
#   )
# )
# Extract log-likelihood for PSIS-LOO cross-validation
log_lik <- extract_log_lik(fit, parameter_name = "log_lik", merge_chains = FALSE)
loo_result <- loo(log_lik, moment_match = TRUE)
print(loo_result)
# Posterior analysis of dynamic weights
bayesplot::mcmc_areas(as.array(fit), pars = c("ar_pos", "ar_neg", "ma_coef")) +
labs(title = "Posterior distributions of AR and MA coefficients")
bayesplot::mcmc_areas(as.array(fit), pars = c("sigma[1]", "sigma[2]", "sigma[3]", "sigma[4]")) +
labs(title = "Posterior distributions of state standard deviations")
bayesplot::mcmc_areas(as.array(fit), pars = c("mu[1]", "mu[2]", "mu[3]", "mu[4]", "lambda")) +
labs(title = "Posterior distributions of state means and smoothing parameter")
bayesplot::mcmc_areas(as.array(fit), pars = c("T[1,1]", "T[2,2]", "T[3,3]", "T[4,4]")) +
labs(title = "Posterior distributions of transition matrix diagonal elements")
# Check posterior distribution of transition matrix
print(fit, pars = "T")
# ===========================
#  Clear Workspace and Setup
# ===========================
rm(list = ls())  # Clear all objects from the workspace
# Set the working directory
setwd('C:/Users/kento/OneDrive - UT Cloud (1)/PhD/Ensemble/20241209')
# ===========================
#   Load External Scripts
# ===========================
# Load necessary R scripts for custom functions and models
source('library.R')       # Contains library imports and setups
source('DGP.R')           # Function for data generation process
source('fit_apriori.R')   # Model fitting function: Apriori
source('fit_BMA.R')       # Model fitting function: Bayesian Model Averaging
source('fit_BPS.R')       # Model fitting function: Bayesian Predictive Stacking
source('fit_BPS2.R')      # Model fitting function: Alternative Bayesian Predictive Stacking
# Load additional libraries using a custom function
library_load()
# ===========================
#    Set Parameters
# ===========================
seed <- 123  # Set the random seed for reproducibility
# Parameters for data simulation
N <- 5
Nt <- 100  # Length of each time series
# ===========================
#    Simulate Data
# ===========================
# Generate data using the custom DGP function
df <- DGP(N = 5, Nt = Nt, seed = seed, train_ratio = 0.6, val_ratio = 0.2)
# Summarize the generated data's regimes
table(c(df$train_regime[1,], df$val_regime[1,], df$test_regime[1,]))
# Visualize the regimes across train, validation, and test sets
plot(c(df$train_regime[1,], df$val_regime[1,], df$test_regime[1,]), type = "l",
main = "Regime Visualization", xlab = "Time", ylab = "Regime")
# ===========================
#   Model Fitting Parameters
# ===========================
n_iter <- 2000   # Number of iterations for Stan model
n_chains <- 4    # Number of chains for Stan model
# ===========================
#      Fit Models
# ===========================
# Fit initial Apriori model
res_apriori <- fit_apriori(data = df, iter = n_iter, chains = n_chains)
# Fit Bayesian Model Averaging (BMA) model
res_BMA <- fit_BMA(data = res_apriori$data_fit, iter = n_iter, chains = n_chains)
# Fit Bayesian Predictive Synthesis (BPS) models
res_BPS <- fit_BPS(data = res_apriori$data_fit, iter = n_iter, chains = n_chains)
res_BPS2 <- fit_BPS2(data = res_apriori$data_fit, iter = n_iter, chains = n_chains)
# Extract results for AR and MA models from Apriori
res_ar <- res_apriori$res_ar
res_ma <- res_apriori$res_ma
# ===========================
#   Check Convergence (Rhat)
# ===========================
# sort(summary(res_ar$fit)$summary[, "Rhat"])
# sort(summary(res_ma$fit)$summary[, "Rhat"])
# sort(summary(res_BMA$fit)$summary[, "Rhat"])
# sort(summary(res_BPS$fit)$summary[, "Rhat"])
# sort(summary(res_BPS2$fit)$summary[, "Rhat"])
# ===========================
#     Compare Models
# ===========================
# Compare models using Leave-One-Out Cross-Validation (LOO) estimates and RMSE
print(data.frame(
Model = "elpd_loo",
AR = res_ar$loo_result$estimates["elpd_loo", "Estimate"],
MA = res_ma$loo_result$estimates["elpd_loo", "Estimate"],
BMA = res_BMA$loo_result$estimates["elpd_loo", "Estimate"],
BPS = res_BPS$loo_result$estimates["elpd_loo", "Estimate"],
BPS2 = res_BPS2$loo_result$estimates["elpd_loo", "Estimate"]
))
print(data.frame(
Model = "p_loo",
AR = res_ar$loo_result$estimates["p_loo", "Estimate"],
MA = res_ma$loo_result$estimates["p_loo", "Estimate"],
BMA = res_BMA$loo_result$estimates["p_loo", "Estimate"],
BPS = res_BPS$loo_result$estimates["p_loo", "Estimate"],
BPS2 = res_BPS2$loo_result$estimates["p_loo", "Estimate"]
))
print(data.frame(
Model = "looic",
AR = res_ar$loo_result$estimates["looic", "Estimate"],
MA = res_ma$loo_result$estimates["looic", "Estimate"],
BMA = res_BMA$loo_result$estimates["looic", "Estimate"],
BPS = res_BPS$loo_result$estimates["looic", "Estimate"],
BPS2 = res_BPS2$loo_result$estimates["looic", "Estimate"]
))
print(data.frame(
Model = "test_rmse",
AR = res_ar$test_rmse,
MA = res_ma$test_rmse,
BMA = res_BMA$test_rmse,
BPS = res_BPS$test_rmse,
BPS2 = res_BPS2$test_rmse
))
# ===========================
#   Model Weight Estimation
# ===========================
# Prepare models and extract log likelihoods
# model_list <- list(res_ar$fit, res_ma$fit)
# log_lik_list <- lapply(model_list, extract_log_lik)
# Compute relative efficiency for stacking method
# r_eff_list <- lapply(model_list, function(x) {
#   ll_array <- extract_log_lik(x, merge_chains = FALSE)
#   relative_eff(exp(ll_array))
# })
# Stacking method weights
# wts1 <- loo_model_weights(log_lik_list,
#                           method = "stacking",
#                           r_eff_list = r_eff_list,
#                           optim_control = list(reltol = 1e-10))
# print(wts1)
# Prepare LOO objects to avoid redundant computations
# loo_list <- lapply(1:length(log_lik_list), function(j) {
#   loo(log_lik_list[[j]], r_eff = r_eff_list[[j]])
# })
# Confirm weights consistency
# wts2 <- loo_model_weights(loo_list,
#                           method = "stacking",
#                           r_eff_list = r_eff_list,
#                           optim_control = list(reltol = 1e-10))
# all.equal(wts1, wts2)
# Assign model names for easier interpretation
# loo_model_weights(setNames(loo_list, c("AR", "MA")))
# Compute weights using alternative methods (pseudo-BMA)
# loo_model_weights(loo_list, method = "pseudobma")
# loo_model_weights(loo_list, method = "pseudobma", BB = FALSE)
# Extract customized BMA results
# colMeans(extract(res_BMA$fit, "w")$w)
# Visualize the regimes across train, validation, and test sets
plot(c(df$train_regime[1,], df$val_regime[1,], df$test_regime[1,]), type = "l",
main = "Regime Visualization", xlab = "Time", ylab = "Regime")
person <- 1
# Summarize the generated data's regimes
table(c(df$train_regime[person,], df$val_regime[person,], df$test_regime[person,]))
# Visualize the regimes across train, validation, and test sets
plot(c(df$train_regime[person,], df$val_regime[person,], df$test_regime[person,]), type = "l",
main = "Regime Visualization", xlab = "Time", ylab = "Regime")
person <- 2
# Summarize the generated data's regimes
table(c(df$train_regime[person,], df$val_regime[person,], df$test_regime[person,]))
# Visualize the regimes across train, validation, and test sets
plot(c(df$train_regime[person,], df$val_regime[person,], df$test_regime[person,]), type = "l",
main = "Regime Visualization", xlab = "Time", ylab = "Regime")
person <- 3
# Summarize the generated data's regimes
table(c(df$train_regime[person,], df$val_regime[person,], df$test_regime[person,]))
# Visualize the regimes across train, validation, and test sets
plot(c(df$train_regime[person,], df$val_regime[person,], df$test_regime[person,]), type = "l",
main = "Regime Visualization", xlab = "Time", ylab = "Regime")
person <- 4
# Summarize the generated data's regimes
table(c(df$train_regime[person,], df$val_regime[person,], df$test_regime[person,]))
# Visualize the regimes across train, validation, and test sets
plot(c(df$train_regime[person,], df$val_regime[person,], df$test_regime[person,]), type = "l",
main = "Regime Visualization", xlab = "Time", ylab = "Regime")
person <- 5
# Summarize the generated data's regimes
table(c(df$train_regime[person,], df$val_regime[person,], df$test_regime[person,]))
# Visualize the regimes across train, validation, and test sets
plot(c(df$train_regime[person,], df$val_regime[person,], df$test_regime[person,]), type = "l",
main = "Regime Visualization", xlab = "Time", ylab = "Regime")
# ===========================
#  Clear Workspace and Setup
# ===========================
rm(list = ls())  # Clear all objects from the workspace
# Set the working directory
setwd('C:/Users/kento/OneDrive - UT Cloud (1)/PhD/Ensemble/20241209')
# ===========================
#  Load External Scripts
# ===========================
source('library.R')
source('DGP.R')
source('fit_apriori.R')
source('fit_BMA.R')
source('fit_BPS.R')
source('fit_BPS2.R')
library_load()
# ===========================
#  Set Parameters
# ===========================
seed <- 123
N <- 5
Nt <- 30
# ===========================
#  Simulate Data
# ===========================
df <- DGP(N = N, Nt = Nt, seed = seed, train_ratio = 0.6, val_ratio = 0.2)
table(c(df$train_regime[1,], df$val_regime[1,], df$test_regime[1,]))
plot(c(df$train_regime[1,], df$val_regime[1,], df$test_regime[1,]),
type = "l",
main = "Regime Visualization",
xlab = "Time",
ylab = "Regime")
# ===========================
#  Model Fitting Parameters
# ===========================
n_iter <- 100
n_chains <- 1
# ===========================
#  Fit Models
# ===========================
res_apriori <- fit_apriori(data = df, iter = n_iter, chains = n_chains)
res_BMA <- fit_BMA(data = res_apriori$data_fit, iter = n_iter, chains = n_chains)
res_BPS <- fit_BPS(data = res_apriori$data_fit, iter = n_iter, chains = n_chains)
res_BPS2 <- fit_BPS2(data = res_apriori$data_fit, iter = n_iter, chains = n_chains)
res_ar <- res_apriori$res_ar
res_ma <- res_apriori$res_ma
# ===========================
#  Check Convergence (Rhat)
# ===========================
rhat_values <- list(
AR = summary(res_ar$fit)$summary[, "Rhat"],
MA = summary(res_ma$fit)$summary[, "Rhat"],
BMA = summary(res_BMA$fit)$summary[, "Rhat"],
BPS = summary(res_BPS$fit)$summary[, "Rhat"],
BPS2 = summary(res_BPS2$fit)$summary[, "Rhat"]
)
lapply(rhat_values, sort)
# ===========================
#  Compare Models
# ===========================
comparison <- data.frame(
Metric = c("elpd_loo", "p_loo", "looic", "test_rmse"),
AR = c(res_ar$loo_result$estimates["elpd_loo", "Estimate"],
res_ar$loo_result$estimates["p_loo", "Estimate"],
res_ar$loo_result$estimates["looic", "Estimate"],
res_ar$test_rmse),
MA = c(res_ma$loo_result$estimates["elpd_loo", "Estimate"],
res_ma$loo_result$estimates["p_loo", "Estimate"],
res_ma$loo_result$estimates["looic", "Estimate"],
res_ma$test_rmse),
BMA = c(res_BMA$loo_result$estimates["elpd_loo", "Estimate"],
res_BMA$loo_result$estimates["p_loo", "Estimate"],
res_BMA$loo_result$estimates["looic", "Estimate"],
res_BMA$test_rmse),
BPS = c(res_BPS$loo_result$estimates["elpd_loo", "Estimate"],
res_BPS$loo_result$estimates["p_loo", "Estimate"],
res_BPS$loo_result$estimates["looic", "Estimate"],
res_BPS$test_rmse),
BPS2 = c(res_BPS2$loo_result$estimates["elpd_loo", "Estimate"],
res_BPS2$loo_result$estimates["p_loo", "Estimate"],
res_BPS2$loo_result$estimates["looic", "Estimate"],
res_BPS2$test_rmse)
)
print(comparison)
# ===========================
#  Clear Workspace and Setup
# ===========================
rm(list = ls())  # Clear all objects from the workspace
# Set the working directory
setwd('C:/Users/kento/OneDrive - UT Cloud (1)/PhD/Ensemble/20241209')
# ===========================
#  Load External Scripts
# ===========================
source('library.R')
source('DGP.R')
source('fit_apriori.R')
source('fit_BMA.R')
source('fit_BPS.R')
source('fit_BPS2.R')
library_load()
# ===========================
#  Set Parameters
# ===========================
seed <- 123
N <- 5
Nt <- 30
# ===========================
#  Simulate Data
# ===========================
df <- DGP(N = N, Nt = Nt, seed = seed, train_ratio = 0.6, val_ratio = 0.2)
table(c(df$train_regime[1,], df$val_regime[1,], df$test_regime[1,]))
plot(c(df$train_regime[1,], df$val_regime[1,], df$test_regime[1,]),
type = "l",
main = "Regime Visualization",
xlab = "Time",
ylab = "Regime")
# ===========================
#  Model Fitting Parameters
# ===========================
n_iter <- 100
n_chains <- 1
# ===========================
#  Fit Models
# ===========================
res_apriori <- fit_apriori(data = df, iter = n_iter, chains = n_chains)
res_BMA <- fit_BMA(data = res_apriori$data_fit, iter = n_iter, chains = n_chains)
res_BPS <- fit_BPS(data = res_apriori$data_fit, iter = n_iter, chains = n_chains)
res_BPS2 <- fit_BPS2(data = res_apriori$data_fit, iter = n_iter, chains = n_chains)
res_ar <- res_apriori$res_ar
res_ma <- res_apriori$res_ma
# ===========================
#  Check Convergence (Rhat)
# ===========================
rhat_values <- list(
AR = summary(res_ar$fit)$summary[, "Rhat"],
MA = summary(res_ma$fit)$summary[, "Rhat"],
BMA = summary(res_BMA$fit)$summary[, "Rhat"],
BPS = summary(res_BPS$fit)$summary[, "Rhat"],
BPS2 = summary(res_BPS2$fit)$summary[, "Rhat"]
)
lapply(rhat_values, sort)
# ===========================
#  Compare Models
# ===========================
comparison <- data.frame(
Metric = c("elpd_loo", "p_loo", "looic", "test_rmse"),
AR = c(res_ar$loo_result$estimates["elpd_loo", "Estimate"],
res_ar$loo_result$estimates["p_loo", "Estimate"],
res_ar$loo_result$estimates["looic", "Estimate"],
res_ar$test_rmse),
MA = c(res_ma$loo_result$estimates["elpd_loo", "Estimate"],
res_ma$loo_result$estimates["p_loo", "Estimate"],
res_ma$loo_result$estimates["looic", "Estimate"],
res_ma$test_rmse),
BMA = c(res_BMA$loo_result$estimates["elpd_loo", "Estimate"],
res_BMA$loo_result$estimates["p_loo", "Estimate"],
res_BMA$loo_result$estimates["looic", "Estimate"],
res_BMA$test_rmse),
BPS = c(res_BPS$loo_result$estimates["elpd_loo", "Estimate"],
res_BPS$loo_result$estimates["p_loo", "Estimate"],
res_BPS$loo_result$estimates["looic", "Estimate"],
res_BPS$test_rmse),
BPS2 = c(res_BPS2$loo_result$estimates["elpd_loo", "Estimate"],
res_BPS2$loo_result$estimates["p_loo", "Estimate"],
res_BPS2$loo_result$estimates["looic", "Estimate"],
res_BPS2$test_rmse)
)
print(comparison)
print(comparison)
