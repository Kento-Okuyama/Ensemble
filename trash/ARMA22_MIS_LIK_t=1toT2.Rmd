---
title: 'true: ARMA(2,2) (AR1+ AR2 + AR3)'
author: "Kento Okuyama"
date: "r Sys.Date()"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

```{r ARMA(2,2) Time Series Data Generation}
# Load the necessary packages
library(forecast)

# Define parameters
n_people <- 10
n_burnins <- 25 
n_timepoints <- 50 

# Initialize a list to store the ARMA(2,2) time series data for 10 people
time_series_list <- list()

# Generate data using an independent ARMA(2,2) process for each person
set.seed(123)
for(i in 1:n_people) {
  ar <- c(0.5, -0.3)
  ma <- c(0.4, -0.2)
  mu <- 0
  sigma <- 1
  e <- rnorm(n_burnins + n_timepoints, mean = mu, sd = sigma)
  data <- numeric(n_burnins + n_timepoints)
  data[1:2] <- e[1:2]
  for(t in 3:(n_burnins + n_timepoints)) {
    data[t] <- mu + ar[1] * (data[t-1] - mu) + ar[2] * (data[t-2] - mu) + e[t] + ma[1] * e[t-1] + ma[2] * e[t-2]
  }
  time_series_list[[i]] <- data[(n_burnins+1):(n_burnins+n_timepoints)]
}

# Plot the time series data for all 10 people
plot(1:n_timepoints, type = 'n', xlim = c(1, n_timepoints), ylim = range(unlist(time_series_list)), main = "ARMA(2,2) Time Series for All Individuals", xlab = "Time", ylab = "Value")
colors <- rainbow(n_people)
for(i in 1:n_people) {
  lines(1:n_timepoints, time_series_list[[i]], col = colors[i], lwd = 1)
}
```

```{r Stan Model Setup}
# Load the packages
library(rstan)
library(loo)

# Prepare the data
data_list <- list(N_people = n_people, N_timepoints = n_timepoints, y = lapply(time_series_list, function(x) x[1:n_timepoints]))

# Set rstan options
options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)
```

```{r AR Models}
# Define the Stan models
stan_model_AR1 <- stan_model(model_code = "
data {
  int<lower=1> N_people;
  int<lower=1> N_timepoints;
  vector[N_timepoints] y[N_people];
}
parameters {
  real phi1;
  real<lower=0> sigma;
  real mu;
}
model {
  phi1 ~ normal(0, 1);
  sigma ~ cauchy(0, 2.5);
  mu ~ normal(0, 10);
  for (j in 1:N_people) {
    for (n in 2:N_timepoints) {
      y[j][n] ~ normal(mu + phi1 * (y[j][n-1] - mu), sigma);
    }
  }
}
generated quantities {
  vector[N_timepoints] log_lik[N_people];
  vector[N_timepoints] y_hat[N_people];
  for (j in 1:N_people) {
    log_lik[j][1] = 0;
    y_hat[j][1] = y[j][1];
    for (n in 2:N_timepoints) {
      log_lik[j][n] = normal_lpdf(y[j][n] | mu + phi1 * (y[j][n-1] - mu), sigma);
      y_hat[j][n] = normal_rng(mu + phi1 * (y[j][n-1] - mu), sigma);
    }
  }
}
")

stan_model_AR2 <- stan_model(model_code = "
data {
  int<lower=1> N_people;
  int<lower=1> N_timepoints;
  vector[N_timepoints] y[N_people];
}
parameters {
  real phi2;
  real<lower=0> sigma;
  real mu;
}
model {
  phi2 ~ normal(0, 1);
  sigma ~ cauchy(0, 2.5);
  mu ~ normal(0, 10);
  for (j in 1:N_people) {
    for (n in 3:N_timepoints) {
      y[j][n] ~ normal(mu + phi2 * (y[j][n-2] - mu), sigma);
    }
  }
}
generated quantities {
  vector[N_timepoints] log_lik[N_people];
  vector[N_timepoints] y_hat[N_people];
  for (j in 1:N_people) {
    log_lik[j][1] = 0;
    log_lik[j][2] = 0;
    y_hat[j][1] = y[j][1];
    y_hat[j][2] = y[j][2];
    for (n in 3:N_timepoints) {
      log_lik[j][n] = normal_lpdf(y[j][n] | mu + phi2 * (y[j][n-2] - mu), sigma);
      y_hat[j][n] = normal_rng(mu + phi2 * (y[j][n-2] - mu), sigma);
    }
  }
}
")

stan_model_AR3 <- stan_model(model_code = "
data {
  int<lower=1> N_people;
  int<lower=1> N_timepoints;
  vector[N_timepoints] y[N_people];
}
parameters {
  real phi3;
  real<lower=0> sigma;
  real mu;
}
model {
  phi3 ~ normal(0, 1);
  sigma ~ cauchy(0, 2.5);
  mu ~ normal(0, 10);
  for (j in 1:N_people) {
    for (n in 4:N_timepoints) {
      y[j][n] ~ normal(mu + phi3 * (y[j][n-3] - mu), sigma);
    }
  }
}
generated quantities {
  vector[N_timepoints] log_lik[N_people];
  vector[N_timepoints] y_hat[N_people];
  for (j in 1:N_people) {
    log_lik[j][1] = 0;
    log_lik[j][2] = 0;
    log_lik[j][3] = 0;
    y_hat[j][1] = y[j][1];
    y_hat[j][2] = y[j][2];
    y_hat[j][3] = y[j][3];
    for (n in 4:N_timepoints) {
      log_lik[j][n] = normal_lpdf(y[j][n] | mu + phi3 * (y[j][n-3] - mu), sigma);
      y_hat[j][n] = normal_rng(mu + phi3 * (y[j][n-3] - mu), sigma);
    }
  }
}
")
```

```{r Model Fitting and Ensemble Predictions}
# Fit each model
fit_combined_AR1 <- sampling(stan_model_AR1, data = data_list, iter = 2000, chains = 4, refresh = 0)
fit_combined_AR2 <- sampling(stan_model_AR2, data = data_list, iter = 2000, chains = 4, refresh = 0)
fit_combined_AR3 <- sampling(stan_model_AR3, data = data_list, iter = 2000, chains = 4, refresh = 0)

# Extract log-likelihoods
log_lik_AR1 <- colMeans(extract_log_lik(fit_combined_AR1, merge_chains = TRUE))
log_lik_AR2 <- colMeans(extract_log_lik(fit_combined_AR2, merge_chains = TRUE))
log_lik_AR3 <- colMeans(extract_log_lik(fit_combined_AR3, merge_chains = TRUE))

# Calculate weights
weights <- exp(-0.5 * c(sum(log_lik_AR1), sum(log_lik_AR2), sum(log_lik_AR3)))
weights <- weights / sum(weights)

# Generate predictions with the ensemble model
ensemble_predictions <- array(0, dim = c(n_people, n_timepoints))
for (i in 1:n_people) {
  for (t in 1:n_timepoints) {
    pred_AR1 <- extract(fit_combined_AR1, pars = "y_hat")$y_hat[,i,t]
    pred_AR2 <- extract(fit_combined_AR2, pars = "y_hat")$y_hat[,i,t]
    pred_AR3 <- extract(fit_combined_AR3, pars = "y_hat")$y_hat[,i,t]
    ensemble_predictions[i, t] <- weights[1] * mean(pred_AR1) + weights[2] * mean(pred_AR2) + weights[3] * mean(pred_AR3)
  }
}

# Plot the predictions of the ensemble model
plot(1:n_timepoints, rep(NA, n_timepoints), type = 'n', xlim = c(1, n_timepoints), ylim = range(ensemble_predictions), main = "Ensemble AR Time Series for All Individuals", xlab = "Time", ylab = "Value")
colors <- rainbow(n_people)
for(i in 1:n_people) {
  lines(1:n_timepoints, ensemble_predictions[i, 1:n_timepoints], col = colors[i], lwd = 1)
}
```

```{r Model Comparison at Final Time Point}
# Calculate mean predictions for each model at final time point
pred_AR1_T <- apply(extract(fit_combined_AR1, pars = "y_hat")$y_hat[,,n_timepoints], 2, mean)
pred_AR2_T <- apply(extract(fit_combined_AR2, pars = "y_hat")$y_hat[,,n_timepoints], 2, mean)
pred_AR3_T <- apply(extract(fit_combined_AR3, pars = "y_hat")$y_hat[,,n_timepoints], 2, mean)

# Calculate prediction errors
mse_AR1_T <- mean((sapply(time_series_list, `[`, n_timepoints) - pred_AR1_T)^2)
mse_AR2_T <- mean((sapply(time_series_list, `[`, n_timepoints) - pred_AR2_T)^2)
mse_AR3_T <- mean((sapply(time_series_list, `[`, n_timepoints) - pred_AR3_T)^2)
mse_ensemble_T <- mean((sapply(time_series_list, `[`, n_timepoints) - ensemble_predictions[, n_timepoints])^2)

# Display the results
print(paste("Average MSE for AR(1):", round(mse_AR1_T, 3)))
print(paste("Average MSE for AR(2):", round(mse_AR2_T, 3)))
print(paste("Average MSE for AR(3):", round(mse_AR3_T, 3)))
print(paste("Average MSE for Ensemble:", round(mse_ensemble_T, 3)))

# Bar graph with ggplot2
library(ggplot2)
mse_data <- data.frame(
  Model = c("AR(1)", "AR(2)", "AR(3)", "Ensemble"),
  MSE = c(mse_AR1_T, mse_AR2_T, mse_AR3_T, mse_ensemble_T)
)
ggplot(mse_data, aes(x = Model, y = MSE, fill = Model)) +
  geom_bar(stat = "identity") +
  scale_fill_manual(values = c("AR(1)" = "red", "AR(2)" = "blue", "AR(3)" = "green", "Ensemble" = "purple")) +
  labs(title = "Average Mean Squared Error Comparison", y = "Average MSE") +
  theme_minimal()
```

```{r Model Comparison Across All Time Points}
# Initialize prediction errors for all timepoints
mse_AR1 <- mse_AR2 <- mse_AR3 <- mse_ensemble <- matrix(0, nrow = n_people, ncol = n_timepoints)

# Calculate prediction errors for each person at each time point
for (i in 1:n_people) {
  for (t in 1:n_timepoints) {
    actual <- time_series_list[[i]][t]
    pred_AR1_t <- extract(fit_combined_AR1, pars = "y_hat")$y_hat[, i, t]
    pred_AR2_t <- extract(fit_combined_AR2, pars = "y_hat")$y_hat[, i, t]
    pred_AR3_t <- extract(fit_combined_AR3, pars = "y_hat")$y_hat[, i, t]
    mse_AR1[i, t] <- mean((actual - pred_AR1_t)^2)
    mse_AR2[i, t] <- mean((actual - pred_AR2_t)^2)
    mse_AR3[i, t] <- mean((actual - pred_AR3_t)^2)
    mse_ensemble[i, t] <- mean((actual - (weights[1] * pred_AR1_t + weights[2] * pred_AR2_t + weights[3] * pred_AR3_t))^2)
  }
}

# Calculate the average prediction errors across all people
avg_mse_AR1 <- colMeans(mse_AR1)
avg_mse_AR2 <- colMeans(mse_AR2)
avg_mse_AR3 <- colMeans(mse_AR3)
avg_mse_ensemble <- colMeans(mse_ensemble)

# Line plot with ggplot2
mse_data_all_timepoints <- data.frame(
  Time = rep(1:n_timepoints, 4),
  MSE = c(avg_mse_AR1, avg_mse_AR2, avg_mse_AR3, avg_mse_ensemble),
  Model = rep(c("AR(1)", "AR(2)", "AR(3)", "Ensemble"), each = n_timepoints)
)
ggplot(mse_data_all_timepoints, aes(x = Time, y = MSE, color = Model, group = Model)) +
  geom_line(size = 0.5) +
  scale_color_manual(values = c("AR(1)" = "red", "AR(2)" = "blue", "AR(3)" = "green", "Ensemble" = "purple")) +
  labs(title = "Mean Squared Error Comparison Across All Time Points", y = "Mean Squared Error", x = "Time") +
  theme_minimal()
```

```{r Model Information Criteria}
# Extract log-likelihoods for each model
log_lik_AR1 <- extract_log_lik(fit_combined_AR1, merge_chains = TRUE)
log_lik_AR2 <- extract_log_lik(fit_combined_AR2, merge_chains = TRUE)
log_lik_AR3 <- extract_log_lik(fit_combined_AR3, merge_chains = TRUE)

# averaged over chains
avg_log_lik_AR1 <- colMeans(log_lik_AR1)
avg_log_lik_AR2 <- colMeans(log_lik_AR2)
avg_log_lik_AR3 <- colMeans(log_lik_AR3)

# Calculate Information Criteria
calculate_IC <- function(log_lik, k) {
  aic <- -2 * sum(log_lik) + 2 * k
  bic <- -2 * sum(log_lik) + log(n_timepoints * n_people) * k
  waic <- waic(matrix(log_lik))
  looic <- loo(matrix(log_lik))
  list(AIC = aic, BIC = bic, WAIC = waic, LOOIC = looic)
}

ICs_AR1 <- calculate_IC(avg_log_lik_AR1, length(extract(fit_combined_AR1)$lp__))
ICs_AR2 <- calculate_IC(avg_log_lik_AR2, length(extract(fit_combined_AR2)$lp__))
ICs_AR3 <- calculate_IC(avg_log_lik_AR3, length(extract(fit_combined_AR3)$lp__))

# Calculate weights based on each criterion
calculate_weights <- function(criteria) {
  criteria_normalized <- as.vector(scale(criteria))
  weights <- exp(-0.5 * criteria_normalized)
  weights / sum(weights)
}

criteria <- list(
  LL = c(sum(avg_log_lik_AR1), sum(avg_log_lik_AR2), sum(avg_log_lik_AR3)),
  AIC = -c(ICs_AR1$AIC, ICs_AR2$AIC, ICs_AR3$AIC),
  BIC = -c(ICs_AR1$BIC, ICs_AR2$BIC, ICs_AR3$BIC),
  WAIC = -c(ICs_AR1$WAIC$waic, ICs_AR2$WAIC$waic, ICs_AR3$WAIC$waic),
  LOOIC = -c(ICs_AR1$LOOIC$looic, ICs_AR2$LOOIC$looic, ICs_AR3$LOOIC$looic),
  MSE = -c(mean(avg_mse_AR1), mean(avg_mse_AR2), mean(avg_mse_AR3))
)

weights <- lapply(criteria, calculate_weights)

# Display the weights for each criterion
weights_df <- do.call(rbind, weights)
colnames(weights_df) <- c("AR(1)", "AR(2)", "AR(3)")
print(weights_df)
```

```{r Model Information Criteria2}
library(rstan)
library(loo)

# Extract log-likelihoods for each model
log_lik_AR1 <- extract_log_lik(fit_combined_AR1, merge_chains = TRUE)
log_lik_AR2 <- extract_log_lik(fit_combined_AR2, merge_chains = TRUE)
log_lik_AR3 <- extract_log_lik(fit_combined_AR3, merge_chains = TRUE)

# Sum log-likelihoods across all data points to get a single vector
log_lik_sum_AR1 <- rowSums(log_lik_AR1)
log_lik_sum_AR2 <- rowSums(log_lik_AR2)
log_lik_sum_AR3 <- rowSums(log_lik_AR3)

# Calculate DIC
calculate_DIC <- function(log_lik_sum) {
  # Compute the deviance for each MCMC sample
  deviance <- -2 * log_lik_sum
  # Mean deviance
  mean_deviance <- mean(deviance)
  # Deviance at the posterior means of the parameters
  deviance_at_mean <- -2 * 
  # Effective number of parameters
  p_DIC <- mean_deviance - deviance_at_mean
  # Calculate DIC
  dic <- mean_deviance + p_DIC
  return(list(DIC = dic, p_DIC = p_DIC))
}

DIC_AR1 <- calculate_DIC(log_lik_sum_AR1)
DIC_AR2 <- calculate_DIC(log_lik_sum_AR2)
DIC_AR3 <- calculate_DIC(log_lik_sum_AR3)

# Calculate WAIC and LOOIC, including effective number of parameters
WAIC_AR1 <- waic(log_lik_AR1)
WAIC_AR2 <- waic(log_lik_AR2)
WAIC_AR3 <- waic(log_lik_AR3)

LOOIC_AR1 <- loo(log_lik_AR1)
LOOIC_AR2 <- loo(log_lik_AR2)
LOOIC_AR3 <- loo(log_lik_AR3)

# Store the information criteria
ICs <- list(
  DIC = c(DIC_AR1$DIC, DIC_AR2$DIC, DIC_AR3$DIC),
  WAIC = c(WAIC_AR1$estimates["waic", "Estimate"], WAIC_AR2$estimates["waic", "Estimate"], WAIC_AR3$estimates["waic", "Estimate"]),
  LOOIC = c(LOOIC_AR1$estimates["looic", "Estimate"], LOOIC_AR2$estimates["looic", "Estimate"], LOOIC_AR3$estimates["looic", "Estimate"]),
  p_eff_DIC = c(DIC_AR1$p_DIC, DIC_AR2$p_DIC, DIC_AR3$p_DIC),
  p_eff_WAIC = c(WAIC_AR1$estimates["p_waic", "Estimate"], WAIC_AR2$estimates["p_waic", "Estimate"], WAIC_AR3$estimates["p_waic", "Estimate"]),
  p_eff_LOOIC = c(LOOIC_AR1$estimates["p_loo", "Estimate"], LOOIC_AR2$estimates["p_loo", "Estimate"], LOOIC_AR3$estimates["p_loo", "Estimate"])
)

# Calculate weights based on each criterion
calculate_weights <- function(criteria) {
  criteria_normalized <- as.vector(scale(criteria))
  weights <- exp(-0.5 * criteria_normalized)
  weights / sum(weights)
}

weights <- lapply(ICs, calculate_weights)

# Display the weights for each criterion
weights_df <- do.call(rbind, weights)
colnames(weights_df) <- c("AR(1)", "AR(2)", "AR(3)")
print(weights_df)


```


```{r Model Information Criteria3}
library(rstan)
library(loo)

# Stanモデルのデータ
data_list <- list(
  N_people = 10,
  N_timepoints = 50,
  y = y_data
)

# Stanモデルのフィッティング
fit_combined_AR1 <- sampling(stan_model_AR1, data = data_list, iter = 2000, chains = 4)
fit_combined_AR2 <- sampling(stan_model_AR2, data = data_list, iter = 2000, chains = 4)
fit_combined_AR3 <- sampling(stan_model_AR3, data = data_list, iter = 2000, chains = 4)

# 事後平均のパラメータの抽出
posterior_mean_AR1 <- summary(fit_combined_AR1)$summary
posterior_mean_AR2 <- summary(fit_combined_AR2)$summary
posterior_mean_AR3 <- summary(fit_combined_AR3)$summary

# 対数尤度の抽出
log_lik_AR1 <- extract_log_lik(fit_combined_AR1, merge_chains = TRUE)
log_lik_AR2 <- extract_log_lik(fit_combined_AR2, merge_chains = TRUE)
log_lik_AR3 <- extract_log_lik(fit_combined_AR3, merge_chains = TRUE)

# 対数尤度の合計
log_lik_sum_AR1 <- rowSums(log_lik_AR1)
log_lik_sum_AR2 <- rowSums(log_lik_AR2)
log_lik_sum_AR3 <- rowSums(log_lik_AR3)

# 事後平均パラメータを使用した対数尤度の計算
calculate_log_lik_posterior <- function(y, mu, phi, sigma) {
  N_people <- nrow(y)
  N_timepoints <- ncol(y)
  log_lik <- matrix(0, nrow = N_people, ncol = N_timepoints)
  for (j in 1:N_people) {
    for (n in 2:N_timepoints) {
      log_lik[j, n] <- dnorm(y[j, n], mean = mu + phi * (y[j, n-1] - mu), sd = sigma, log = TRUE)
    }
  }
  return(log_lik)
}

log_lik_posterior_AR1 <- calculate_log_lik_posterior(y_data, 
                                                     posterior_mean_AR1["mu", "mean"], 
                                                     posterior_mean_AR1["phi1", "mean"], 
                                                     posterior_mean_AR1["sigma", "mean"])

log_lik_posterior_AR2 <- calculate_log_lik_posterior(y_data, 
                                                     posterior_mean_AR2["mu", "mean"], 
                                                     posterior_mean_AR2["phi2", "mean"], 
                                                     posterior_mean_AR2["sigma", "mean"])

log_lik_posterior_AR3 <- calculate_log_lik_posterior(y_data, 
                                                     posterior_mean_AR3["mu", "mean"], 
                                                     posterior_mean_AR3["phi3", "mean"], 
                                                     posterior_mean_AR3["sigma", "mean"])

# DICの計算
calculate_DIC <- function(log_lik_sum, log_lik_posterior) {
  # 全サンプルに対するデビアンスの平均
  mean_deviance <- mean(-2 * log_lik_sum)
  # 事後平均パラメータによるデビアンス
  deviance_at_mean <- -2 * sum(log_lik_posterior)
  # 有効パラメータ数
  p_DIC <- mean_deviance - deviance_at_mean
  # DICの計算
  dic <- mean_deviance + p_DIC
  return(list(DIC = dic, p_DIC = p_DIC))
}

DIC_AR1 <- calculate_DIC(log_lik_sum_AR1, log_lik_posterior_AR1)
DIC_AR2 <- calculate_DIC(log_lik_sum_AR2, log_lik_posterior_AR2)
DIC_AR3 <- calculate_DIC(log_lik_sum_AR3, log_lik_posterior_AR3)

# WAICとLOOICの計算
WAIC_AR1 <- waic(log_lik_AR1)
WAIC_AR2 <- waic(log_lik_AR2)
WAIC_AR3 <- waic(log_lik_AR3)

LOOIC_AR1 <- loo(log_lik_AR1)
LOOIC_AR2 <- loo(log_lik_AR2)
LOOIC_AR3 <- loo(log_lik_AR3)

# 情報量基準のリスト
ICs <- list(
  DIC = c(DIC_AR1$DIC, DIC_AR2$DIC, DIC_AR3$DIC),
  WAIC = c(WAIC_AR1$estimates["waic", "Estimate"], WAIC_AR2$estimates["waic", "Estimate"], WAIC_AR3$estimates["waic", "Estimate"]),
  LOOIC = c(LOOIC_AR1$estimates["looic", "Estimate"], LOOIC_AR2$estimates["looic", "Estimate"], LOOIC_AR3$estimates["looic", "Estimate"]),
  p_eff_DIC = c(DIC_AR1$p_DIC, DIC_AR2$p_DIC, DIC_AR3$p_DIC),
  p_eff_WAIC = c(WAIC_AR1$estimates["p_waic", "Estimate"], WAIC_AR2$estimates["p_waic", "Estimate"], WAIC_AR3$estimates["p_waic", "Estimate"]),
  p_eff_LOOIC = c(LOOIC_AR1$estimates["p_loo", "Estimate"], LOOIC_AR2$estimates["p_loo", "Estimate"], LOOIC_AR3$estimates["p_loo", "Estimate"])
)

# 各基準に基づく重みの計算
calculate_weights <- function(criteria) {
  criteria_normalized <- as.vector(scale(criteria))
  weights <- exp(-0.5 * criteria_normalized)
  weights / sum(weights)
}

weights <- lapply(ICs, calculate_weights)

# 各基準に基づく重みの表示
weights_df <- do.call(rbind, weights)
colnames(weights_df) <- c("AR(1)", "AR(2)", "AR(3)")
print(weights_df)

```